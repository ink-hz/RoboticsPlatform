#!/usr/bin/env python3
"""
MVPå¹³å°ç®€åŒ–æ€§èƒ½æµ‹è¯•è„šæœ¬ï¼ˆæ— å¤–éƒ¨ä¾èµ–ï¼‰
"""

import urllib.request
import urllib.parse
import json
import time
import threading
import statistics
import random
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor

class SimplePerformanceTester:
    """ç®€åŒ–æ€§èƒ½æµ‹è¯•å™¨"""
    
    def __init__(self, base_url="http://localhost:8080"):
        self.base_url = base_url
        self.results = {
            'latencies': [],
            'success_count': 0,
            'error_count': 0,
            'start_time': None,
            'end_time': None
        }
        self.lock = threading.Lock()
    
    def send_request(self, method, endpoint, data=None):
        """å‘é€HTTPè¯·æ±‚"""
        url = f"{self.base_url}{endpoint}"
        start_time = time.time()
        
        try:
            if data:
                data_bytes = json.dumps(data).encode('utf-8')
                req = urllib.request.Request(url, data=data_bytes, method=method)
                req.add_header('Content-Type', 'application/json')
            else:
                req = urllib.request.Request(url, method=method)
            
            with urllib.request.urlopen(req, timeout=10) as response:
                response.read()
                status = response.status
            
            latency = (time.time() - start_time) * 1000  # æ¯«ç§’
            
            with self.lock:
                self.results['latencies'].append(latency)
                if status == 200:
                    self.results['success_count'] += 1
                else:
                    self.results['error_count'] += 1
            
            return status == 200, latency
            
        except Exception as e:
            latency = (time.time() - start_time) * 1000
            with self.lock:
                self.results['error_count'] += 1
                self.results['latencies'].append(latency)
            return False, latency
    
    def data_ingestion_worker(self, worker_id, duration_seconds, requests_per_second=5):
        """æ•°æ®æ‘„å…¥å·¥ä½œçº¿ç¨‹"""
        end_time = time.time() + duration_seconds
        request_interval = 1.0 / requests_per_second
        
        while time.time() < end_time:
            # ç”Ÿæˆæµ‹è¯•æ•°æ®
            sensor_data = {
                "device_id": f"perf_test_{worker_id}_{random.randint(1, 100)}",
                "sensor_type": random.choice(["temperature", "humidity", "pressure", "cpu"]),
                "value": round(random.uniform(0, 100), 2),
                "metadata": {
                    "test_type": "performance",
                    "worker_id": worker_id,
                    "timestamp": datetime.now().isoformat()
                }
            }
            
            # å‘é€è¯·æ±‚
            self.send_request('POST', '/api/data/ingest', sensor_data)
            
            # æ§åˆ¶è¯·æ±‚é¢‘ç‡
            time.sleep(request_interval)
    
    def query_worker(self, worker_id, duration_seconds, requests_per_second=2):
        """æŸ¥è¯¢å·¥ä½œçº¿ç¨‹"""
        end_time = time.time() + duration_seconds
        request_interval = 1.0 / requests_per_second
        
        while time.time() < end_time:
            # éšæœºæŸ¥è¯¢è®¾å¤‡
            device_id = f"perf_test_{random.randint(1, 10)}_{random.randint(1, 100)}"
            self.send_request('GET', f'/api/data/{device_id}?limit=5')
            
            # é—´æ­‡æ€§åˆ†ææŸ¥è¯¢
            if random.random() < 0.3:
                self.send_request('GET', '/api/analytics/summary')
            
            # é—´æ­‡æ€§æŒ‡æ ‡æŸ¥è¯¢
            if random.random() < 0.1:
                self.send_request('GET', '/api/metrics')
            
            time.sleep(request_interval)
    
    def run_load_test(self, concurrent_users=10, duration_seconds=60, test_type="mixed"):
        """è¿è¡Œè´Ÿè½½æµ‹è¯•"""
        print(f"ğŸš€ Starting {test_type} load test...")
        print(f"   Concurrent users: {concurrent_users}")
        print(f"   Duration: {duration_seconds}s")
        
        self.reset_results()
        self.results['start_time'] = time.time()
        
        with ThreadPoolExecutor(max_workers=concurrent_users) as executor:
            futures = []
            
            for i in range(concurrent_users):
                if test_type == "ingestion":
                    future = executor.submit(self.data_ingestion_worker, i, duration_seconds, 3)
                elif test_type == "query":
                    future = executor.submit(self.query_worker, i, duration_seconds, 2)
                else:  # mixed
                    # 70% æ‘„å…¥ï¼Œ30% æŸ¥è¯¢
                    if i < concurrent_users * 0.7:
                        future = executor.submit(self.data_ingestion_worker, i, duration_seconds, 2)
                    else:
                        future = executor.submit(self.query_worker, i, duration_seconds, 1)
                
                futures.append(future)
            
            # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
            for future in futures:
                future.result()
        
        self.results['end_time'] = time.time()
        self.calculate_metrics()
        return self.results
    
    def run_spike_test(self, spike_requests=200):
        """è¿è¡Œå³°å€¼æµ‹è¯•"""
        print(f"âš¡ Starting spike test...")
        print(f"   Spike requests: {spike_requests}")
        
        self.reset_results()
        self.results['start_time'] = time.time()
        
        def spike_worker(i):
            """å³°å€¼æµ‹è¯•å·¥ä½œå‡½æ•°"""
            sensor_data = {
                "device_id": f"spike_test_{i}",
                "sensor_type": "load_test",
                "value": random.uniform(0, 100),
                "metadata": {"test": "spike", "request_id": i}
            }
            return self.send_request('POST', '/api/data/ingest', sensor_data)
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å‘é€è¯·æ±‚
        with ThreadPoolExecutor(max_workers=50) as executor:
            futures = [executor.submit(spike_worker, i) for i in range(spike_requests)]
            
            # ç­‰å¾…æ‰€æœ‰è¯·æ±‚å®Œæˆ
            for future in futures:
                future.result()
        
        self.results['end_time'] = time.time()
        self.calculate_metrics()
        return self.results
    
    def calculate_metrics(self):
        """è®¡ç®—æ€§èƒ½æŒ‡æ ‡"""
        if not self.results['latencies']:
            return
        
        duration = self.results['end_time'] - self.results['start_time']
        total_requests = self.results['success_count'] + self.results['error_count']
        
        self.results['duration'] = duration
        self.results['throughput'] = total_requests / duration if duration > 0 else 0
        self.results['error_rate'] = (self.results['error_count'] / total_requests * 100) if total_requests > 0 else 0
        self.results['avg_latency'] = statistics.mean(self.results['latencies'])
        
        if len(self.results['latencies']) > 1:
            self.results['p50_latency'] = statistics.median(self.results['latencies'])
            sorted_latencies = sorted(self.results['latencies'])
            self.results['p95_latency'] = sorted_latencies[int(len(sorted_latencies) * 0.95)]
            self.results['p99_latency'] = sorted_latencies[int(len(sorted_latencies) * 0.99)]
        else:
            self.results['p50_latency'] = self.results['avg_latency']
            self.results['p95_latency'] = self.results['avg_latency']
            self.results['p99_latency'] = self.results['avg_latency']
        
        self.results['max_latency'] = max(self.results['latencies'])
        self.results['min_latency'] = min(self.results['latencies'])
    
    def print_results(self, test_name="Performance Test"):
        """æ‰“å°æµ‹è¯•ç»“æœ"""
        print(f"\n{'='*60}")
        print(f"ğŸ“Š {test_name} Results")
        print(f"{'='*60}")
        print(f"ğŸ• Duration: {self.results.get('duration', 0):.2f}s")
        print(f"ğŸ“ˆ Throughput: {self.results.get('throughput', 0):.2f} req/sec")
        print(f"âœ… Successful requests: {self.results['success_count']}")
        print(f"âŒ Failed requests: {self.results['error_count']}")
        print(f"ğŸ“‰ Error rate: {self.results.get('error_rate', 0):.2f}%")
        print(f"\nâ±ï¸  Latency Statistics (ms):")
        print(f"   Average: {self.results.get('avg_latency', 0):.2f}")
        print(f"   P50 (Median): {self.results.get('p50_latency', 0):.2f}")
        print(f"   P95: {self.results.get('p95_latency', 0):.2f}")
        print(f"   P99: {self.results.get('p99_latency', 0):.2f}")
        print(f"   Min: {self.results.get('min_latency', 0):.2f}")
        print(f"   Max: {self.results.get('max_latency', 0):.2f}")
        print(f"{'='*60}")
    
    def reset_results(self):
        """é‡ç½®æµ‹è¯•ç»“æœ"""
        self.results = {
            'latencies': [],
            'success_count': 0,
            'error_count': 0,
            'start_time': None,
            'end_time': None
        }

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ¯ MVP Platform Simple Performance Testing")
    print("="*60)
    
    # å¥åº·æ£€æŸ¥
    tester = SimplePerformanceTester()
    try:
        success, latency = tester.send_request('GET', '/health')
        if not success:
            print("âŒ Platform health check failed")
            return
    except Exception as e:
        print(f"âŒ Cannot connect to platform: {e}")
        return
    
    print("âœ… Platform health check passed")
    
    # æ€§èƒ½æµ‹è¯•åºåˆ—
    tests = [
        ("Data Ingestion Load Test", "ingestion", {"concurrent_users": 8, "duration_seconds": 30}),
        ("Mixed Workload Test", "mixed", {"concurrent_users": 6, "duration_seconds": 45}),
        ("Query Load Test", "query", {"concurrent_users": 4, "duration_seconds": 20}),
    ]
    
    all_results = {}
    
    for test_name, test_type, params in tests:
        print(f"\nğŸš¦ Starting {test_name}...")
        try:
            results = tester.run_load_test(test_type=test_type, **params)
            tester.print_results(test_name)
            all_results[test_name] = results.copy()
        except Exception as e:
            print(f"âŒ {test_name} failed: {e}")
        
        # æµ‹è¯•é—´éš”
        print("\nâ³ Cooling down for 5 seconds...")
        time.sleep(5)
    
    # å³°å€¼æµ‹è¯•
    print(f"\nğŸš¦ Starting Spike Test...")
    try:
        spike_results = tester.run_spike_test(100)
        tester.print_results("Spike Test")
        all_results["Spike Test"] = spike_results.copy()
    except Exception as e:
        print(f"âŒ Spike test failed: {e}")
    
    # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
    generate_summary_report(all_results)

def generate_summary_report(results):
    """ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š"""
    if not results:
        return
    
    print(f"\nğŸ¯ Overall Performance Summary")
    print(f"{'='*60}")
    
    avg_throughput = sum(r.get('throughput', 0) for r in results.values()) / len(results)
    avg_error_rate = sum(r.get('error_rate', 0) for r in results.values()) / len(results)
    avg_latency = sum(r.get('avg_latency', 0) for r in results.values()) / len(results)
    
    total_requests = sum(r.get('success_count', 0) + r.get('error_count', 0) for r in results.values())
    total_errors = sum(r.get('error_count', 0) for r in results.values())
    
    print(f"ğŸ“Š Test Summary:")
    print(f"   Total tests run: {len(results)}")
    print(f"   Total requests: {total_requests}")
    print(f"   Total errors: {total_errors}")
    print(f"\nğŸ“ˆ Average Performance:")
    print(f"   Throughput: {avg_throughput:.2f} req/sec")
    print(f"   Latency: {avg_latency:.2f} ms")
    print(f"   Error rate: {avg_error_rate:.2f}%")
    
    # æ€§èƒ½ç­‰çº§è¯„ä¼°
    if avg_throughput > 50 and avg_error_rate < 5:
        grade = "ğŸ† EXCELLENT"
    elif avg_throughput > 25 and avg_error_rate < 10:
        grade = "âœ… GOOD"
    elif avg_throughput > 10 and avg_error_rate < 20:
        grade = "âš ï¸  ACCEPTABLE"
    else:
        grade = "âŒ NEEDS IMPROVEMENT"
    
    print(f"\nğŸ–ï¸  Performance Grade: {grade}")
    print(f"{'='*60}")
    
    # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_data = {
        "timestamp": datetime.now().isoformat(),
        "summary": {
            "avg_throughput": avg_throughput,
            "avg_latency": avg_latency,
            "avg_error_rate": avg_error_rate,
            "total_requests": total_requests,
            "total_errors": total_errors,
            "performance_grade": grade
        },
        "detailed_results": results
    }
    
    report_file = f"perf_report_{timestamp}.json"
    try:
        with open(report_file, 'w') as f:
            json.dump(report_data, f, indent=2, default=str)
        print(f"ğŸ“„ Detailed report saved to: {report_file}")
    except Exception as e:
        print(f"âš ï¸  Could not save report: {e}")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nğŸ›‘ Performance test interrupted by user")
    except Exception as e:
        print(f"\nâŒ Performance test failed: {e}")